{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import essential libriries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the tweetsid as they wont be used in the analytical process\n",
    "df = df.drop(['tweetid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 2 columns):\n",
      "sentiment    15819 non-null int64\n",
      "message      15819 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 247.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# check a quick summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Seems like we have have no missing values in the data. so we will check using \n",
    "isnull().sum() to verify that the're no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It seems like we have 4 sentiments ranging from -1 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df[df['sentiment']==2]\n",
    "pro = df[df['sentiment']==1]\n",
    "neutral = df[df['sentiment']==0]\n",
    "anti = df[df['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the distribution of the target variables\n",
    "sns.countplot(df['sentiment'], label = \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ from the plot we can see that most of the tweets supports the man-made climate change.\n",
    "followed by tweets tha that do not believe in a man-made climate change. The difference \n",
    "in the number of tweets for other sentiments is not that big as compared to others. So,\n",
    "our model might predict tweets that support man-made climate chage better than other tweets.\n",
    "We might need to Up sample, Down sample or use SMOTE at a later stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @StephenSchlegel: she's thinking about how she's going to die because your husband doesn't believe in climate change https://t.co/SjoFoNÃ¢â‚¬Â¦\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove web address, @mentions, #hashtags, RT, and also remove additional white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mentions\n",
    "mentions = r'@[A-Za-z0-9]+'\n",
    "\n",
    "df['message'] = df['message'].replace(mentions,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove web address\n",
    "url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "\n",
    "df['message'] = df['message'].replace(url,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hashtags\n",
    "hashtags = r'#[A-Za-z0-9]+'\n",
    "\n",
    "df['message'] = df['message'].replace(hashtags,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only letters\n",
    "letters = r\"[^a-zA-Z.!?']\"\n",
    "\n",
    "df['message'] = df['message'].replace(letters,' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only letters (pantuation)\n",
    "#letters = r'[^a-zA-Z.!?']'\n",
    "#df['message'] = df['message'].replace(letters,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT   Researchers say we have three years to ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>WIRED        was a pivotal year in the war o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RT   It's       and a racist  sexist  climate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "1          1  It's not like we lack evidence of anthropogeni...\n",
       "2          2  RT   Researchers say we have three years to ac...\n",
       "3          1    WIRED        was a pivotal year in the war o...\n",
       "4          1  RT   It's       and a racist  sexist  climate ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove pantuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(message):\n",
    "    return ''.join([tweet for tweet in message if tweet not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt   shes thinking about how shes going to die because your husband doesnt believe in climate change        '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place additional spaces with a single space\n",
    "space = r' +'\n",
    "\n",
    "df['message'] = df['message'].replace(space,' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15814</td>\n",
       "      <td>1</td>\n",
       "      <td>rt they took down the material on global warmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15815</td>\n",
       "      <td>2</td>\n",
       "      <td>rt how climate change could be breaking up a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15816</td>\n",
       "      <td>0</td>\n",
       "      <td>notiven rt nytimesworld what does trump actual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15817</td>\n",
       "      <td>-1</td>\n",
       "      <td>rt hey liberals the climate change crap is a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15818</td>\n",
       "      <td>0</td>\n",
       "      <td>rt cannon s climate change equation in screens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message\n",
       "0              1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1              1  its not like we lack evidence of anthropogenic...\n",
       "2              2  rt researchers say we have three years to act ...\n",
       "3              1   wired was a pivotal year in the war on climat...\n",
       "4              1  rt its and a racist sexist climate change deny...\n",
       "...          ...                                                ...\n",
       "15814          1  rt they took down the material on global warmi...\n",
       "15815          2  rt how climate change could be breaking up a m...\n",
       "15816          0  notiven rt nytimesworld what does trump actual...\n",
       "15817         -1  rt hey liberals the climate change crap is a h...\n",
       "15818          0  rt cannon s climate change equation in screens...\n",
       "\n",
       "[15819 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "\n",
    "tokeniser = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['tokenized'] = df.apply(lambda row: word_tokenize(row['message']), axis=1)\n",
    "df['tokenized'] = df['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...  \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_word(message, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(tweet) for tweet in message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = df['tokenized'].apply(most_common_word, args=(lemmatizer, ))\n",
    "#lemmatise_token = token.apply(most_common_word, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>[wired, wa, a, pivotal, year, in, the, war, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "      <td>[rt, it, and, a, racist, sexist, climate, chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [wired, wa, a, pivotal, year, in, the, war, on...  \n",
       "4  [rt, it, and, a, racist, sexist, climate, chan...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>it not like we lack evidence of anthropogenic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>rt researcher say we have three year to act on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>wired wa a pivotal year in the war on climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "      <td>rt it and a racist sexist climate change denyi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...   \n",
       "\n",
       "                                               lemma  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1  it not like we lack evidence of anthropogenic ...  \n",
       "2  rt researcher say we have three year to act on...  \n",
       "3  wired wa a pivotal year in the war on climate ...  \n",
       "4  rt it and a racist sexist climate change denyi...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df['lemma']\n",
    "# I am now gonna the lemma column to a column of string and not a list of strings, since i get an error\n",
    "def sentences(lemma):\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "df['lemma'] = df['lemma'].apply(sentences)\n",
    "df.head()\n",
    "#X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemma']\n",
    "\n",
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 13074)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.toarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12655, 13074)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense #connects all the layers\n",
    "\n",
    "model = Sequential()\n",
    "# try 40,30,30 and then work from there\n",
    "model.add(Dense(100, input_dim = X_train.shape[-1], activation = 'relu'))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(4, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'scipy.sparse.csr.csr_matrix'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-da46883d3bf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mepochs_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1038\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[0;32m   1039\u001b[0m           data_adapter.train_validation_split(\n\u001b[1;32m-> 1040\u001b[1;33m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     raise ValueError(\n\u001b[0;32m   1375\u001b[0m         \u001b[1;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m         \"arrays, found following types in the input: {}\".format(unsplitable))\n\u001b[0m\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'scipy.sparse.csr.csr_matrix'>]"
     ]
    }
   ],
   "source": [
    "epochs_hist = model.fit(X_train, y_train, epochs = 350, batch_size = 30, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  79   32  152   15]\n",
      " [  13  148  223   41]\n",
      " [  19   62 1486  188]\n",
      " [   3   19  194  490]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.28      0.40       278\n",
      "           0       0.57      0.35      0.43       425\n",
      "           1       0.72      0.85      0.78      1755\n",
      "           2       0.67      0.69      0.68       706\n",
      "\n",
      "    accuracy                           0.70      3164\n",
      "   macro avg       0.66      0.54      0.57      3164\n",
      "weighted avg       0.69      0.70      0.68      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10000)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0  278    0]\n",
      " [   0    0  425    0]\n",
      " [   0    0 1755    0]\n",
      " [   0    0  706    0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       278\n",
      "           0       0.00      0.00      0.00       425\n",
      "           1       0.55      1.00      0.71      1755\n",
      "           2       0.00      0.00      0.00       706\n",
      "\n",
      "    accuracy                           0.55      3164\n",
      "   macro avg       0.14      0.25      0.18      3164\n",
      "weighted avg       0.31      0.55      0.40      3164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear', random_state=0)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 137   44   85   12]\n",
      " [  33  201  166   25]\n",
      " [  69  156 1370  160]\n",
      " [  10   44  162  490]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.49      0.52       278\n",
      "           0       0.45      0.47      0.46       425\n",
      "           1       0.77      0.78      0.77      1755\n",
      "           2       0.71      0.69      0.70       706\n",
      "\n",
      "    accuracy                           0.69      3164\n",
      "   macro avg       0.62      0.61      0.61      3164\n",
      "weighted avg       0.69      0.69      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
    "svc_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  73   21  175    9]\n",
      " [   6  136  265   18]\n",
      " [   4   40 1599  112]\n",
      " [   3   16  216  471]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.26      0.40       278\n",
      "           0       0.64      0.32      0.43       425\n",
      "           1       0.71      0.91      0.80      1755\n",
      "           2       0.77      0.67      0.72       706\n",
      "\n",
      "    accuracy                           0.72      3164\n",
      "   macro avg       0.74      0.54      0.59      3164\n",
      "weighted avg       0.73      0.72      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  84   50  119   25]\n",
      " [  24  206  160   35]\n",
      " [  62  262 1254  177]\n",
      " [  22   79  182  423]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.30      0.36       278\n",
      "           0       0.35      0.48      0.40       425\n",
      "           1       0.73      0.71      0.72      1755\n",
      "           2       0.64      0.60      0.62       706\n",
      "\n",
      "    accuracy                           0.62      3164\n",
      "   macro avg       0.54      0.53      0.53      3164\n",
      "weighted avg       0.63      0.62      0.62      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=1000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=1000, criterion='entropy')\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  80   43  141   14]\n",
      " [   7  179  215   24]\n",
      " [  15  122 1490  128]\n",
      " [   6   34  197  469]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.29      0.41       278\n",
      "           0       0.47      0.42      0.45       425\n",
      "           1       0.73      0.85      0.78      1755\n",
      "           2       0.74      0.66      0.70       706\n",
      "\n",
      "    accuracy                           0.70      3164\n",
      "   macro avg       0.67      0.56      0.59      3164\n",
      "weighted avg       0.70      0.70      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
