{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import essential libriries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\User\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the tweetsid as they wont be used in the analytical process\n",
    "df = df.drop(['tweetid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 2 columns):\n",
      "sentiment    15819 non-null int64\n",
      "message      15819 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 247.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# check a quick summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Seems like we have have no missing values in the data. so we will check using \n",
    "isnull().sum() to verify that the're no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It seems like we have 4 sentiments ranging from -1 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = df[df['sentiment']==2]\n",
    "#pro = df[df['sentiment']==1]\n",
    "#neutral = df[df['sentiment']==0]\n",
    "#anti = df[df['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the distribution of the target variables\n",
    "sns.countplot(df['sentiment'], label = \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ from the plot we can see that most of the tweets supports the man-made climate change.\n",
    "followed by tweets tha that do not believe in a man-made climate change. The difference \n",
    "in the number of tweets for other sentiments is not that big as compared to others. So,\n",
    "our model might predict tweets that support man-made climate chage better than other tweets.\n",
    "We might need to Up sample, Down sample or use SMOTE at a later stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @StephenSchlegel: she's thinking about how she's going to die because your husband doesn't believe in climate change https://t.co/SjoFoNÃ¢â‚¬Â¦\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove web address, @mentions, #hashtags, RT, and also remove additional white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mentions\n",
    "mentions = r'@[A-Za-z0-9]+'\n",
    "\n",
    "df['message'] = df['message'].replace(mentions,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove web address\n",
    "url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "\n",
    "df['message'] = df['message'].replace(url,'url', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hashtags\n",
    "hashtags = r'#[A-Za-z0-9]+'\n",
    "\n",
    "df['message'] = df['message'].replace(hashtags,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only letters\n",
    "letters = r\"[^a-zA-Z.!?']\"\n",
    "\n",
    "df['message'] = df['message'].replace(letters,' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only letters (pantuation)\n",
    "#letters = r'[^a-zA-Z.!?']'\n",
    "#df['message'] = df['message'].replace(letters,'', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT   Researchers say we have three years to ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>WIRED        was a pivotal year in the war o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RT   It's       and a racist  sexist  climate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "1          1  It's not like we lack evidence of anthropogeni...\n",
       "2          2  RT   Researchers say we have three years to ac...\n",
       "3          1    WIRED        was a pivotal year in the war o...\n",
       "4          1  RT   It's       and a racist  sexist  climate ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove pantuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(message):\n",
    "    return ''.join([tweet for tweet in message if tweet not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt   shes thinking about how shes going to die because your husband doesnt believe in climate change url       '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place additional spaces with a single space\n",
    "space = r' +'\n",
    "\n",
    "df['message'] = df['message'].replace(space,' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15814</td>\n",
       "      <td>1</td>\n",
       "      <td>rt they took down the material on global warmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15815</td>\n",
       "      <td>2</td>\n",
       "      <td>rt how climate change could be breaking up a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15816</td>\n",
       "      <td>0</td>\n",
       "      <td>notiven rt nytimesworld what does trump actual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15817</td>\n",
       "      <td>-1</td>\n",
       "      <td>rt hey liberals the climate change crap is a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15818</td>\n",
       "      <td>0</td>\n",
       "      <td>rt cannon s climate change equation in screens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message\n",
       "0              1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1              1  its not like we lack evidence of anthropogenic...\n",
       "2              2  rt researchers say we have three years to act ...\n",
       "3              1   wired was a pivotal year in the war on climat...\n",
       "4              1  rt its and a racist sexist climate change deny...\n",
       "...          ...                                                ...\n",
       "15814          1  rt they took down the material on global warmi...\n",
       "15815          2  rt how climate change could be breaking up a m...\n",
       "15816          0  notiven rt nytimesworld what does trump actual...\n",
       "15817         -1  rt hey liberals the climate change crap is a h...\n",
       "15818          0  rt cannon s climate change equation in screens...\n",
       "\n",
       "[15819 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "\n",
    "tokeniser = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['tokenized'] = df.apply(lambda row: word_tokenize(row['message']), axis=1)\n",
    "df['tokenized'] = df['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...  \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_word(message, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(tweet) for tweet in message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = df['tokenized'].apply(most_common_word, args=(lemmatizer, ))\n",
    "#lemmatise_token = token.apply(most_common_word, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>[wired, wa, a, pivotal, year, in, the, war, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "      <td>[rt, it, and, a, racist, sexist, climate, chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [wired, wa, a, pivotal, year, in, the, war, on...  \n",
       "4  [rt, it, and, a, racist, sexist, climate, chan...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=90000)#max_features=50, min_df=2) #CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>it not like we lack evidence of anthropogenic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>rt researcher say we have three year to act on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wired was a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>wired wa a pivotal year in the war on climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rt its and a racist sexist climate change deny...</td>\n",
       "      <td>[rt, its, and, a, racist, sexist, climate, cha...</td>\n",
       "      <td>rt it and a racist sexist climate change denyi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1          1  its not like we lack evidence of anthropogenic...   \n",
       "2          2  rt researchers say we have three years to act ...   \n",
       "3          1   wired was a pivotal year in the war on climat...   \n",
       "4          1  rt its and a racist sexist climate change deny...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4  [rt, its, and, a, racist, sexist, climate, cha...   \n",
       "\n",
       "                                               lemma  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1  it not like we lack evidence of anthropogenic ...  \n",
       "2  rt researcher say we have three year to act on...  \n",
       "3  wired wa a pivotal year in the war on climate ...  \n",
       "4  rt it and a racist sexist climate change denyi...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df['lemma']\n",
    "# I am now gonna the lemma column to a column of string and not a list of strings, since i get an error\n",
    "def sentences(lemma):\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "df['lemma'] = df['lemma'].apply(sentences)\n",
    "df.head()\n",
    "#X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemma']\n",
    "\n",
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 13086)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turn the space matrix into a dataframe\n",
    "df2 = pd.DataFrame.sparse.from_spmatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13077</th>\n",
       "      <th>13078</th>\n",
       "      <th>13079</th>\n",
       "      <th>13080</th>\n",
       "      <th>13081</th>\n",
       "      <th>13082</th>\n",
       "      <th>13083</th>\n",
       "      <th>13084</th>\n",
       "      <th>13085</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13087 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  13077  13078  13079  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "   13080  13081  13082  13083  13084  13085  sentiment  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0          1  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0          1  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0          1  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0          1  \n",
       "\n",
       "[5 rows x 13087 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sentiment'] = df['sentiment']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = scipy.sparse.csc_matrix(df2)\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df2[df2['sentiment']==2]\n",
    "pro = df2[df2['sentiment']==1]\n",
    "neutral = df2[df2['sentiment']==0]\n",
    "anti = df2[df2['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(new)*1.5)\n",
    "\n",
    "df_new = resample(new,\n",
    "                 replace= True,\n",
    "                 n_samples= sample_size,\n",
    "                 random_state=42)\n",
    "df_pro = resample(pro,\n",
    "                 replace= False, # down sample\n",
    "                 n_samples= sample_size,\n",
    "                 random_state=42)\n",
    "df_neutral = resample(neutral,\n",
    "                 replace= True,\n",
    "                 n_samples= sample_size,\n",
    "                 random_state=42)\n",
    "df_anti = resample(anti,\n",
    "                 replace= True,\n",
    "                 n_samples= sample_size,\n",
    "                 random_state=42)\n",
    "\n",
    "#df_sampled = pd.concat([new, pro, df_neutral, df_anti])\n",
    "df_sampled = pd.concat([df_new, df_pro, df_neutral, df_anti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13077</th>\n",
       "      <th>13078</th>\n",
       "      <th>13079</th>\n",
       "      <th>13080</th>\n",
       "      <th>13081</th>\n",
       "      <th>13082</th>\n",
       "      <th>13083</th>\n",
       "      <th>13084</th>\n",
       "      <th>13085</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21840 rows × 13087 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1    2   3   4   5   6    7   8    9  ...  13077  13078  13079  \\\n",
       "13776  0.0 NaN  NaN NaN NaN NaN NaN  NaN NaN  0.0  ...    NaN    NaN    NaN   \n",
       "15247  0.0 NaN  NaN NaN NaN NaN NaN  NaN NaN  0.0  ...    NaN    NaN    NaN   \n",
       "3533   0.0 NaN  NaN NaN NaN NaN NaN  NaN NaN  0.0  ...    NaN    NaN    NaN   \n",
       "5570   0.0 NaN  NaN NaN NaN NaN NaN  NaN NaN  0.0  ...    NaN    NaN    NaN   \n",
       "4824   0.0 NaN  NaN NaN NaN NaN NaN  NaN NaN  0.0  ...    NaN    NaN    NaN   \n",
       "...    ...  ..  ...  ..  ..  ..  ..  ...  ..  ...  ...    ...    ...    ...   \n",
       "14141  NaN NaN  0.0 NaN NaN NaN NaN  0.0 NaN  NaN  ...    NaN    NaN    NaN   \n",
       "5087   NaN NaN  0.0 NaN NaN NaN NaN  0.0 NaN  NaN  ...    NaN    NaN    NaN   \n",
       "14722  NaN NaN  0.0 NaN NaN NaN NaN  0.0 NaN  NaN  ...    NaN    NaN    NaN   \n",
       "4442   NaN NaN  0.0 NaN NaN NaN NaN  0.0 NaN  NaN  ...    NaN    NaN    NaN   \n",
       "4570   NaN NaN  0.0 NaN NaN NaN NaN  0.0 NaN  NaN  ...    NaN    NaN    NaN   \n",
       "\n",
       "       13080  13081  13082  13083  13084  13085  sentiment  \n",
       "13776    NaN    0.0    NaN    NaN    NaN    NaN          2  \n",
       "15247    NaN    0.0    NaN    NaN    NaN    NaN          2  \n",
       "3533     NaN    0.0    NaN    NaN    NaN    NaN          2  \n",
       "5570     NaN    0.0    NaN    NaN    NaN    NaN          2  \n",
       "4824     NaN    0.0    NaN    NaN    NaN    NaN          2  \n",
       "...      ...    ...    ...    ...    ...    ...        ...  \n",
       "14141    NaN    0.0    NaN    NaN    NaN    NaN         -1  \n",
       "5087     NaN    0.0    NaN    NaN    NaN    NaN         -1  \n",
       "14722    NaN    0.0    NaN    NaN    NaN    NaN         -1  \n",
       "4442     NaN    0.0    NaN    NaN    NaN    NaN         -1  \n",
       "4570     NaN    0.0    NaN    NaN    NaN    NaN         -1  \n",
       "\n",
       "[21840 rows x 13087 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mini data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df_sampled.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13077</th>\n",
       "      <th>13078</th>\n",
       "      <th>13079</th>\n",
       "      <th>13080</th>\n",
       "      <th>13081</th>\n",
       "      <th>13082</th>\n",
       "      <th>13083</th>\n",
       "      <th>13084</th>\n",
       "      <th>13085</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21840 rows × 13087 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  13077  13078  \\\n",
       "13776  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "15247  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "3533   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5570   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4824   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "14141  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5087   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "14722  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4442   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4570   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "       13079  13080  13081  13082  13083  13084  13085  sentiment  \n",
       "13776    0.0    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "15247    0.0    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "3533     0.0    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "5570     0.0    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "4824     0.0    0.0    0.0    0.0    0.0    0.0    0.0          2  \n",
       "...      ...    ...    ...    ...    ...    ...    ...        ...  \n",
       "14141    0.0    0.0    0.0    0.0    0.0    0.0    0.0         -1  \n",
       "5087     0.0    0.0    0.0    0.0    0.0    0.0    0.0         -1  \n",
       "14722    0.0    0.0    0.0    0.0    0.0    0.0    0.0         -1  \n",
       "4442     0.0    0.0    0.0    0.0    0.0    0.0    0.0         -1  \n",
       "4570     0.0    0.0    0.0    0.0    0.0    0.0    0.0         -1  \n",
       "\n",
       "[21840 rows x 13087 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21840, 13086)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sampled.iloc[:,:-1].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sampled.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17472, 13086)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_ann = X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.keras\n",
    "#from keras.models import Sequential \n",
    "#from keras.layers import Dense #connects all the layers\n",
    "\n",
    "#model = Sequential()\n",
    "# try 40,30,30 and then work from there\n",
    "#model.add(Dense(100, input_dim = X_train_ann.shape[-1], activation = 'relu'))\n",
    "#model.add(Dense(70, activation='relu'))\n",
    "#model.add(Dense(70, activation='relu'))\n",
    "#model.add(Dense(1, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs_hist = model.fit(X_train_ann, y_train, epochs = 50, batch_size = 30, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(epochs_hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(epochs_hist.history['loss'])\n",
    "#plt.plot(epochs_hist.history['val_loss'])\n",
    "\n",
    "#plt.title('Model Loss Progression During Training/Validation')\n",
    "#plt.ylabel('Training and Validation Losses')\n",
    "#plt.xlabel('Epoch Number')\n",
    "#plt.legend(['Training Loss', 'Validation Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "#svc = SVC(kernel='linear', random_state=0)\n",
    "#svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test,y_pred))\n",
    "#print('\\n')\n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_rbf = SVC(kernel = 'rbf', gamma=1, C=10)\n",
    "svc_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1070    5    8    0]\n",
      " [   5  994   69   11]\n",
      " [  21   75  941   84]\n",
      " [   3   10   78  994]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98      1083\n",
      "           0       0.92      0.92      0.92      1079\n",
      "           1       0.86      0.84      0.85      1121\n",
      "           2       0.91      0.92      0.91      1085\n",
      "\n",
      "    accuracy                           0.92      4368\n",
      "   macro avg       0.92      0.92      0.92      4368\n",
      "weighted avg       0.91      0.92      0.92      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(svc_rbf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10541</td>\n",
       "      <td>RT @BrittanyBohrer: Brb, writing a poem about ...</td>\n",
       "      <td>895714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10542</td>\n",
       "      <td>2016: the year climate change came home: Durin...</td>\n",
       "      <td>875167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10543</td>\n",
       "      <td>RT @loop_vanuatu: Pacific countries positive a...</td>\n",
       "      <td>78329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10544</td>\n",
       "      <td>RT @xanria_00018: You’re so hot, you must be t...</td>\n",
       "      <td>867455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10545</td>\n",
       "      <td>RT @chloebalaoing: climate change is a global ...</td>\n",
       "      <td>470892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  tweetid\n",
       "0      Europe will now be looking to China to make su...   169760\n",
       "1      Combine this with the polling of staffers re c...    35326\n",
       "2      The scary, unimpeachable evidence that climate...   224985\n",
       "3      @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4      RT @FakeWillMoore: 'Female orgasms cause globa...   872928\n",
       "...                                                  ...      ...\n",
       "10541  RT @BrittanyBohrer: Brb, writing a poem about ...   895714\n",
       "10542  2016: the year climate change came home: Durin...   875167\n",
       "10543  RT @loop_vanuatu: Pacific countries positive a...    78329\n",
       "10544  RT @xanria_00018: You’re so hot, you must be t...   867455\n",
       "10545  RT @chloebalaoing: climate change is a global ...   470892\n",
       "\n",
       "[10546 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message    0\n",
       "tweetid    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].replace(mentions,'', regex = True)\n",
    "\n",
    "df['message'] = df['message'].replace(url,'url', regex = True)\n",
    "\n",
    "df['message'] = df['message'].replace(hashtags,'', regex = True)\n",
    "\n",
    "df['message'] = df['message'].replace(letters,' ', regex = True)\n",
    "\n",
    "df['message'] = df['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(remove_punctuation)\n",
    "\n",
    "df['message'] = df['message'].replace(space,' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = df['tokenized'].apply(most_common_word, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = df['lemma'].apply(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' putin got to you too jill trump doesnt believe in climate change at all thinks its s hoax'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = TfidfVectorizer(stop_words='english', min_df=2) #CountVectorizer(stop_words='english')\n",
    "X_t = df['lemma']\n",
    "\n",
    "X_t = cv.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = pd.DataFrame.sparse.from_spmatrix(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 13086)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean data \n",
    "X_t.to_csv('df_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.03 GiB for an array with shape (13086, 10546) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-45b0723155cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_rbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5441\u001b[0m         \"\"\"\n\u001b[0;32m   5442\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5445\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, items)\u001b[0m\n\u001b[0;32m    820\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    838\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.03 GiB for an array with shape (13086, 10546) and data type float64"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_t.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetid = df['tweetid']\n",
    "\n",
    "d = {'sentiment':y_pred}\n",
    "y_pred_t = pd.DataFrame(d)\n",
    "y_pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.concat([tweetid, y_pred_t], axis=1)\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('third_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jomoon/starter-notebook-edsa-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
